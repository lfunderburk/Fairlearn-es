# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018 - 2021, Fairlearn contributors
# This file is distributed under the same license as the Fairlearn package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Fairlearn \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-12-15 12:35-0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../auto_examples/plot_new_metrics.rst:13
msgid ""
"Click :ref:`here <sphx_glr_download_auto_examples_plot_new_metrics.py>` "
"to download the full example code"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:23
msgid "Metrics with Multiple Features"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:27
msgid ""
"This notebook demonstrates the new API for metrics, which supports "
"multiple sensitive and conditional features. This example does not "
"contain a proper discussion of how fairness relates to the dataset used, "
"although it does highlight issues which users may want to consider when "
"analysing their datasets."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:33
msgid ""
"We are going to consider a lending scenario, supposing that we have a "
"model which predicts whether or not a particular customer will repay a "
"loan. This could be used as the basis of deciding whether or not to offer"
" that customer a loan. With traditional metrics, we would assess the "
"model using:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:39
msgid "The 'true' values from the test set"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:40
msgid "The model predictions from the test set"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:42
msgid ""
"Our fairness metrics compute group-based fairness statistics. To use "
"these, we also need categorical columns from the test set. For this "
"example, we will include:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:46
msgid "The sex of each individual (two unique values)"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:47
msgid "The race of each individual (three unique values)"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:48
msgid "The credit score band of each individual (three unique values)"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:49
msgid "Whether the loan is considered 'large' or 'small'"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:51
msgid ""
"An individual's sex and race should not affect a lending decision, but it"
" would be legitimate to consider an individual's credit score and the "
"relative size of the loan which they desired."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:55
msgid ""
"A real scenario will be more complicated, but this will serve to "
"illustrate the use of the new metrics."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:59
msgid "Getting the Data"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:61
msgid ""
"*This section may be skipped. It simply creates a dataset for "
"illustrative purposes*"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:64
msgid ""
"We will use the well-known UCI 'Adult' dataset as the basis of this "
"demonstration. This is not for a lending scenario, but we will regard it "
"as one for the purposes of this example. We will use the existing 'race' "
"and 'sex' columns (trimming the former to three unique values), and "
"manufacture credit score bands and loan sizes from other columns. We "
"start with some uncontroversial `import` statements:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:102
msgid "Next, we import the data:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:122
msgid ""
"For purposes of clarity, we consolidate the 'race' column to have three "
"unique values:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:148
#: ../../auto_examples/plot_new_metrics.rst:210
#: ../../auto_examples/plot_new_metrics.rst:502
#: ../../auto_examples/plot_new_metrics.rst:581
#: ../../auto_examples/plot_new_metrics.rst:852
#: ../../auto_examples/plot_new_metrics.rst:963
#: ../../auto_examples/plot_new_metrics.rst:994
#: ../../auto_examples/plot_new_metrics.rst:1024
#: ../../auto_examples/plot_new_metrics.rst:1054
#: ../../auto_examples/plot_new_metrics.rst:1084
#: ../../auto_examples/plot_new_metrics.rst:1248
#: ../../auto_examples/plot_new_metrics.rst:1278
#: ../../auto_examples/plot_new_metrics.rst:1323
#: ../../auto_examples/plot_new_metrics.rst:1760
#: ../../auto_examples/plot_new_metrics.rst:2218
#: ../../auto_examples/plot_new_metrics.rst:2296
msgid "Out:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:165
msgid ""
"Now, we manufacture the columns for the credit score band and requested "
"loan size. These are wholly constructed, and not part of the actual "
"dataset in any way. They are simply for illustrative purposes."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:343
msgid ""
"Now that we have imported our dataset and manufactured a few features, we"
" can perform some more conventional processing. To avoid the problem of "
"`data leakage "
"<https://en.wikipedia.org/wiki/Leakage_(machine_learning)>`_, we need to "
"split the data into training and test sets before applying any transforms"
" or scaling:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:379
msgid ""
"Next, we build two :class:`~sklearn.pipeline.Pipeline` objects to process"
" the columns, one for numeric data, and the other for categorical data. "
"Both impute missing values; the difference is whether the data are scaled"
" (numeric columns) or one-hot encoded (categorical columns). Imputation "
"of missing values should generally be done with care, since it could "
"potentially introduce biases. Of course, removing rows with missing data "
"could also cause trouble, if particular subgroups have poorer data "
"quality."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:422
msgid ""
"With our preprocessor defined, we can now build a new pipeline which "
"includes an Estimator:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:449
msgid ""
"With the pipeline fully defined, we can first train it with the training "
"data, and then generate predictions from the test data."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:472
msgid "Analysing the Model with Metrics"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:474
msgid ""
"After our data manipulations and model training, we have the following "
"from our test set:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:477
msgid "A vector of true values called ``y_test``"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:478
msgid "A vector of model predictions called ``y_pred``"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:479
msgid "A DataFrame of categorical features relevant to fairness called ``A_test``"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:481
msgid ""
"In a traditional model analysis, we would now look at some metrics "
"evaluated on the entire dataset. Suppose in this case, the relevant "
"metrics are :func:`fairlearn.metrics.selection_rate` and "
":func:`sklearn.metrics.fbeta_score` (with ``beta=0.6``). We can evaluate "
"these metrics directly:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:514
msgid ""
"We know that there are sensitive features in our data, and we want to "
"ensure that we're not harming individuals due to membership in any of "
"these groups. For this purpose, Fairlearn provides the "
":class:`fairlearn.metrics.MetricFrame` class. Let us construct an "
"instance of this class, and then look at its capabilities:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:544
msgid ""
"The :class:`fairlearn.metrics.MetricFrame` object requires a minimum of "
"four arguments:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:547
msgid "The underlying metric function(s) to be evaluated"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:548
msgid "The true values"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:549
msgid "The predicted values"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:550
msgid "The sensitive feature values"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:552
msgid ""
"These are all passed as arguments to the constructor. If more than one "
"underlying metric is required (as in this case), then we must provide "
"them in a dictionary."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:556
msgid ""
"The underlying metrics must have a signature ``fn(y_true, y_pred)``, so "
"we have to use :func:`functools.partial` on ``fbeta_score()`` to furnish "
"``beta=0.6`` (we will show how to pass in extra array arguments such as "
"sample weights shortly)."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:561
msgid ""
"We will now take a closer look at the "
":class:`fairlearn.metrics.MetricFrame` object. First, there is the "
"``overall`` property, which contains the metrics evaluated on the entire "
"dataset. We see that this contains the same values calculated above:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:595
msgid ""
"The other property in the :class:`fairlearn.metrics.MetricFrame` object "
"is ``by_group``. This contains the metrics evaluated on each subgroup "
"defined by the categories in the ``sensitive_features=`` argument. Note "
"that :func:`fairlearn.metrics.count` can be used to display the number of"
" data points in each subgroup. In this case, we have results for males "
"and females:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:667
msgid ""
"We can immediately see a substantial disparity in the selection rate "
"between males and females."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:670
msgid ""
"We can also create another :class:`fairlearn.metrics.MetricFrame` object "
"using race as the sensitive feature:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:692
msgid "The ``overall`` property is unchanged:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:709
msgid ""
"The ``by_group`` property now contains the metrics evaluated based on the"
" 'race' column:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:783
msgid ""
"We see that there is also a significant disparity in selection rates when"
" grouping by race."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:789
msgid "Sample weights and other arrays"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:791
msgid ""
"We noted above that the underlying metric functions passed to the "
":class:`fairlearn.metrics.MetricFrame` constructor need to be of the form"
" ``fn(y_true, y_pred)`` - we do not support scalar arguments such as "
"``pos_label=`` or ``beta=`` in the constructor. Such arguments should be "
"bound into a new function using :func:`functools.partial`, and the result"
" passed in. However, we do support arguments which have one entry for "
"each sample, with an array of sample weights being the most common "
"example. These are divided into subgroups along with ``y_true`` and "
"``y_pred``, and passed along to the underlying metric."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:802
msgid ""
"To use these arguments, we pass in a dictionary as the ``sample_params=``"
" argument of the constructor. Let us generate some random weights, and "
"pass these along:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:834
msgid "We can inspect the overall values, and check they are as expected:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:866
msgid "We can also see the effect on the metric being evaluated on the subgroups:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:934
msgid "Quantifying Disparities"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:936
msgid ""
"We now know that our model is selecting individuals who are female far "
"less often than individuals who are male. There is a similar effect when "
"examining the results by race, with blacks being selected far less often "
"than whites (and those classified as 'other'). However, there are many "
"cases where presenting all these numbers at once will not be useful (for "
"example, a high level dashboard which is monitoring model performance). "
"Fairlearn provides several means of aggregating metrics across the "
"subgroups, so that disparities can be readily quantified."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:945
msgid ""
"The simplest of these aggregations is ``group_min()``, which reports the "
"minimum value seen for a subgroup for each underlying metric (we also "
"provide ``group_max()``). This is useful if there is a mandate that \"no "
"subgroup should have an ``fbeta_score()`` of less than 0.6.\" We can "
"evaluate the minimum values easily:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:977
msgid ""
"As noted above, the selection rates varies greatly by race and by sex. "
"This can be quantified in terms of a difference between the subgroup with"
" the highest value of the metric, and the subgroup with the lowest value."
" For this, we provide the method ``difference(method='between_groups)``:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1008
msgid ""
"We can also evaluate the difference relative to the corresponding overall"
" value of the metric. In this case we take the absolute value, so that "
"the result is always positive:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1038
msgid ""
"There are situations where knowing the ratios of the metrics evaluated on"
" the subgroups is more useful. For this we have the ``ratio()`` method. "
"We can take the ratios between the minimum and maximum values of each "
"metric:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1068
msgid ""
"We can also compute the ratios relative to the overall value for each "
"metric. Analogous to the differences, the ratios are always in the range "
":math:`[0,1]`:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1099
msgid "Intersections of Features"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1101
msgid ""
"So far we have only considered a single sensitive feature at a time, and "
"we have already found some serious issues in our example data. However, "
"sometimes serious issues can be hiding in intersections of features. For "
"example, the `Gender Shades project <https://www.media.mit.edu/projects"
"/gender-shades/overview/>`_ found that facial recognition algorithms "
"performed worse for blacks than whites, and also worse for women than men"
" (despite overall high accuracy score). Moreover, performance on black "
"females was *terrible*. We can examine the intersections of sensitive "
"features by passing multiple columns to the "
":class:`fairlearn.metrics.MetricFrame` constructor:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1132
msgid ""
"The overall values are unchanged, but the ``by_group`` table now shows "
"the intersections between subgroups:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1230
msgid ""
"The aggregations are still performed across all subgroups for each "
"metric, so each continues to reduce to a single value. If we look at the "
"``group_min()``, we see that we violate the mandate we specified for the "
"``fbeta_score()`` suggested above (for females with a race of 'Other' in "
"fact):"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1262
msgid ""
"Looking at the ``ratio()`` method, we see that the disparity is worse "
"(specifically between white males and black females, if we check in the "
"``by_group`` table):"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1293
msgid "Control Features"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1295
msgid ""
"There is a further way we can slice up our data. We have (*completely "
"made up*) features for the individuals' credit scores (in three bands) "
"and also the size of the loan requested (large or small). In our loan "
"scenario, it is acceptable that individuals with high credit scores are "
"selected more often than individuals with low credit scores. However, "
"within each credit score band, we do not want a disparity between (say) "
"black females and white males. To example these cases, we have the "
"concept of *control features*."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1304
msgid ""
"Control features are introduced by the ``control_features=`` argument to "
"the :class:`fairlearn.metrics.MetricFrame` object:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1337
msgid ""
"This has an immediate effect on the ``overall`` property. Instead of "
"having one value for each metric, we now have a value for each unique "
"value of the control feature:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1412
msgid "The ``by_group`` property is similarly expanded:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1591
msgid ""
"The aggregates are also evaluated once for each group identified by the "
"control feature:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1665
msgid "And:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1738
msgid ""
"In our data, we see that we have a dearth of positive results for high "
"income non-whites, which significantly affects the aggregates."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1742
msgid "We can continue adding more control features:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1791
msgid "The ``overall`` property now splits into more values:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:1886
msgid ""
"As does the ``by_groups`` property, where ``NaN`` values indicate that "
"there were no samples in the cell:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:2190
msgid ""
"The aggregates behave similarly. By this point, we are having significant"
" issues with under-populated intersections. Consider:"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:2267
msgid ""
"Recall that ``NaN`` indicates that there were no individuals in a cell - "
"``member_counts()`` will not even have been called."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:2273
msgid "Exporting from MetricFrame"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:2275
msgid ""
"Sometimes, we need to extract our data for use in other tools. For this, "
"we can use the :py:meth:`pandas.DataFrame.to_csv` method, since the "
":py:meth:`~fairlearn.metrics.MetricFrame.by_group` property will be a "
":class:`pandas.DataFrame` (or in a few cases, it will be a "
":class:`pandas.Series`, but that has a similar "
":py:meth:`~pandas.Series.to_csv` method):"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:2326
msgid ""
"The :py:meth:`pandas.DataFrame.to_csv` method has a large number of "
"arguments to control the exported CSV. For example, it can write directly"
" to a CSV file, rather than returning a string (as shown above)."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:2331
msgid ""
"The :meth:`~fairlearn.metrics.MetricFrame.overall` property can be "
"handled similarly, in the cases that it is not a scalar."
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:2337
msgid "**Total running time of the script:** ( 0 minutes  9.525 seconds)"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:2352
msgid ""
":download:`Download Python source code: plot_new_metrics.py "
"<plot_new_metrics.py>`"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:2358
msgid ""
":download:`Download Jupyter notebook: plot_new_metrics.ipynb "
"<plot_new_metrics.ipynb>`"
msgstr ""

#: ../../auto_examples/plot_new_metrics.rst:2365
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

