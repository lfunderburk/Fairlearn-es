# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018 - 2021, Fairlearn contributors
# This file is distributed under the same license as the Fairlearn package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Fairlearn \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-12-15 12:35-0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.7.0\n"

#: ../../user_guide/mitigation.rst:4
msgid "Mitigation"
msgstr ""

#: ../../user_guide/mitigation.rst:6
msgid "Fairlearn contains the following algorithms for mitigating unfairness:"
msgstr ""

#: ../../user_guide/mitigation.rst:13
msgid "algorithm"
msgstr ""

#: ../../user_guide/mitigation.rst:14
msgid "description"
msgstr ""

#: ../../user_guide/mitigation.rst:15
msgid "binary classification"
msgstr ""

#: ../../user_guide/mitigation.rst:16
msgid "regression"
msgstr ""

#: ../../user_guide/mitigation.rst:17
msgid "supported fairness definitions"
msgstr ""

#: ../../user_guide/mitigation.rst:18
msgid ":class:`~fairlearn.reductions.ExponentiatedGradient`"
msgstr ""

#: ../../user_guide/mitigation.rst:19
msgid ""
"A wrapper (reduction) approach to fair classification described in *A "
"Reductions* *Approach to Fair Classification* [#2]_."
msgstr ""

#: ../../user_guide/mitigation.rst:21 ../../user_guide/mitigation.rst:22
#: ../../user_guide/mitigation.rst:30 ../../user_guide/mitigation.rst:31
#: ../../user_guide/mitigation.rst:39 ../../user_guide/mitigation.rst:45
#: ../../user_guide/mitigation.rst:46
msgid "✔"
msgstr ""

#: ../../user_guide/mitigation.rst:23 ../../user_guide/mitigation.rst:32
msgid "DP, EO, TPRP, FPRP, ERP, BGL"
msgstr ""

#: ../../user_guide/mitigation.rst:24
msgid ":class:`~fairlearn.reductions.GridSearch`"
msgstr ""

#: ../../user_guide/mitigation.rst:25
msgid ""
"A wrapper (reduction) approach described in Section 3.4 of *A Reductions*"
" *Approach to Fair Classification* [#2]_. For regression it acts as a "
"grid-search variant of the algorithm described in Section 5 of *Fair "
"Regression: Quantitative Definitions and Reduction-based* *Algorithms* "
"[#1]_."
msgstr ""

#: ../../user_guide/mitigation.rst:33
msgid ":class:`~fairlearn.postprocessing.ThresholdOptimizer`"
msgstr ""

#: ../../user_guide/mitigation.rst:34
msgid ""
"Postprocessing algorithm based on the paper *Equality of Opportunity* *in"
" Supervised Learning* [#3]_. This technique takes as input an existing "
"classifier and the sensitive feature, and derives a monotone "
"transformation of the classifier's prediction to enforce the specified "
"parity constraints."
msgstr ""

#: ../../user_guide/mitigation.rst:40 ../../user_guide/mitigation.rst:47
msgid "✘"
msgstr ""

#: ../../user_guide/mitigation.rst:41
msgid "DP, EO, TPRP, FPRP"
msgstr ""

#: ../../user_guide/mitigation.rst:42
msgid ":class:`~fairlearn.preprocessing.CorrelationRemover`"
msgstr ""

#: ../../user_guide/mitigation.rst:43
msgid ""
"Preprocessing algorithm that removes correlation between sensitive "
"features and non-sensitive features through linear transformations."
msgstr ""

#: ../../user_guide/mitigation.rst:49
msgid ""
"DP refers to *demographic parity*, EO to *equalized odds*, TPRP to *true "
"positive rate parity*, FPRP to *false positive rate parity*, ERP to "
"*error rate parity*, and BGL to *bounded group loss*. For more "
"information on the definitions refer to "
":ref:`fairness_in_machine_learning`. To request additional algorithms or "
"fairness definitions, please open a `new issue "
"<https://github.com/fairlearn/fairlearn/issues>`_ on GitHub."
msgstr ""

#: ../../user_guide/mitigation.rst:59
msgid ""
"Fairlearn mitigation algorithms largely follow the `conventions of "
"scikit-learn <https://scikit-"
"learn.org/stable/developers/contributing.html#different-objects>`_, "
"meaning that they implement the :code:`fit` method to train a model and "
"the :code:`predict` method to make predictions. However, in contrast with"
" `scikit-learn <https://scikit-learn.org/stable/glossary.html#term-"
"estimator>`_, Fairlearn algorithms can produce randomized predictors. "
"Randomization of predictions is required to satisfy many definitions of "
"fairness. Because of randomization, it is possible to get different "
"outputs from the predictor's :code:`predict` method on identical data. "
"For each of our algorithms, we provide explicit access to the probability"
" distribution used for randomization."
msgstr ""

#: ../../user_guide/mitigation.rst:73
msgid "Preprocessing"
msgstr ""

#: ../../user_guide/mitigation.rst:80
msgid "Postprocessing"
msgstr ""

#: ../../user_guide/mitigation.rst:87
msgid "Reductions"
msgstr ""

#: ../../user_guide/mitigation.rst:91
msgid ""
"On a high level, the reduction algorithms within Fairlearn enable "
"unfairness mitigation for an arbitrary machine learning model with "
"respect to user-provided fairness constraints. All of the constraints "
"currently supported by reduction algorithms are group-fairness "
"constraints. For more information on the supported fairness constraints "
"refer to :ref:`constraints_binary_classification` and "
":ref:`constraints_regression`."
msgstr ""

#: ../../user_guide/mitigation.rst:100
msgid ""
"The choice of a fairness metric and fairness constraints is a crucial "
"step in the AI development and deployment, and choosing an unsuitable "
"constraint can lead to more harms. For a broader discussion of fairness "
"as a sociotechnical challenge and how to view Fairlearn in this context "
"refer to :ref:`fairness_in_machine_learning`."
msgstr ""

#: ../../user_guide/mitigation.rst:107
msgid ""
"The reductions approach for classification seeks to reduce binary "
"classification subject to fairness constraints to a sequence of weighted "
"classification problems (see [#2]_), and similarly for regression (see "
"[#1]_). As a result, the reduction algorithms in Fairlearn only require a"
" wrapper access to any \"base\" learning algorithm. By this we mean that "
"the \"base\" algorithm only needs to implement :code:`fit` and "
":code:`predict` methods, as any standard scikit-learn estimator, but it "
"does not need to have any knowledge of the desired fairness constraints "
"or sensitive features."
msgstr ""

#: ../../user_guide/mitigation.rst:116
msgid "From an API perspective this looks as follows in all situations"
msgstr ""

#: ../../user_guide/mitigation.rst:122
msgid ""
"Fairlearn doesn't impose restrictions on the referenced "
":code:`base_estimator` other than the existence of :code:`fit` and "
":code:`predict` methods. At the moment, the :code:`base_estimator`'s "
":code:`fit` method also needs to provide a :code:`sample_weight` argument"
" which the reductions techniques use to reweight samples. In the future "
"Fairlearn will provide functionality to handle this even without a "
":code:`sample_weight` argument."
msgstr ""

#: ../../user_guide/mitigation.rst:130
msgid ""
"Before looking more into reduction algorithms, this section reviews the "
"supported fairness constraints. All of them are expressed as objects "
"inheriting from the base class :code:`Moment`. :code:`Moment`'s main "
"purpose is to calculate the constraint violation of a current set of "
"predictions through its :code:`gamma` function as well as to provide "
":code:`signed_weights` that are used to relabel and reweight samples."
msgstr ""

#: ../../user_guide/mitigation.rst:140
msgid "Fairness constraints for binary classification"
msgstr ""

#: ../../user_guide/mitigation.rst:142
msgid ""
"All supported fairness constraints for binary classification inherit from"
" :code:`UtilityParity`. They are based on some underlying metric called "
"*utility*, which can be evaluated on individual data points and is "
"averaged over various groups of data points to form the *utility parity* "
"constraint of the form"
msgstr ""

#: ../../user_guide/mitigation.rst:148
msgid "\\text{utility}_{a,e} = \\text{utility}_e \\quad \\forall a, e"
msgstr ""

#: ../../user_guide/mitigation.rst:152
msgid ""
"where :math:`a` is a sensitive feature value and :math:`e` is an *event* "
"identifier. Each data point has only one value of a sensitive feature, "
"and belongs to at most one event. In many examples, there is only a "
"single event :math:`*`, which includes all the data points. Other "
"examples of events include :math:`Y=0` and :math:`Y=1`. The utility "
"parity requires that the mean utility within each event equals the mean "
"utility of each group whose sensitive feature is :math:`a` within that "
"event."
msgstr ""

#: ../../user_guide/mitigation.rst:161
msgid ""
"The class :code:`UtilityParity` implements constraints that allow some "
"amount of violation of the utility parity constraints, where the maximum "
"allowed violation is specified either as a difference or a ratio."
msgstr ""

#: ../../user_guide/mitigation.rst:166
msgid ""
"The *difference-based relaxation* starts out by representing the utility "
"parity constraints as pairs of inequalities"
msgstr ""

#: ../../user_guide/mitigation.rst:170
msgid ""
"\\text{utility}_{a,e} - \\text{utility}_{e} \\leq 0 \\quad \\forall a, "
"e\\\\\n"
"-\\text{utility}_{a,e} + \\text{utility}_{e} \\leq 0 \\quad \\forall a, e"
msgstr ""

#: ../../user_guide/mitigation.rst:175
msgid ""
"and then replaces zero on the right-hand side with a value specified as "
":code:`difference_bound`. The resulting constraints are instantiated as"
msgstr ""

#: ../../user_guide/mitigation.rst:181
msgid ""
"Note that satisfying these constraints does not mean that the difference "
"between the groups with the highest and smallest utility in each event is"
" bounded by :code:`difference_bound`. The value of "
":code:`difference_bound` instead bounds the difference between the "
"utility of each group and the overall mean utility within each event. "
"This, however, implies that the difference between groups in each event "
"is at most twice the value of :code:`difference_bound`."
msgstr ""

#: ../../user_guide/mitigation.rst:190
msgid "The *ratio-based relaxation* relaxes the parity constraint as"
msgstr ""

#: ../../user_guide/mitigation.rst:193
msgid ""
"r \\leq \\dfrac{\\text{utility}_{a,e}}{\\text{utility}_e} \\leq "
"\\dfrac{1}{r} \\quad \\forall a, e"
msgstr ""

#: ../../user_guide/mitigation.rst:197
#, python-format
msgid ""
"for some value of :math:`r` in (0,1]. For example, if :math:`r=0.9`, this"
" means that within each event :math:`0.9 \\cdot \\text{utility}_{a,e} "
"\\leq \\text{utility}_e`, i.e., the utility for each group needs to be at"
" least 90% of the overall utility for the event, and :math:`0.9 \\cdot "
"\\text{utility}_e \\leq \\text{utility}_{a,e}`, i.e., the overall utility"
" for the event needs to be at least 90% of each group's utility."
msgstr ""

#: ../../user_guide/mitigation.rst:204
msgid "The two ratio constraints can be rewritten as"
msgstr ""

#: ../../user_guide/mitigation.rst:206
msgid ""
"- \\text{utility}_{a,e} + r \\cdot \\text{utility}_e \\leq 0 \\quad "
"\\forall a, e \\\\\n"
"r \\cdot \\text{utility}_{a,e} - \\text{utility}_e \\leq 0 \\quad "
"\\forall a, e"
msgstr ""

#: ../../user_guide/mitigation.rst:211
msgid ""
"When instantiating the ratio constraints, we use :code:`ratio_bound` for "
":math:`r`, and also allow further relaxation by replacing the zeros on "
"the right hand side by some non-negative :code:`ratio_bound_slack`. The "
"resulting instantiation looks as"
msgstr ""

#: ../../user_guide/mitigation.rst:218
msgid ""
"Similarly to the difference constraints, the ratio constraints do not "
"directly bound the ratio between the pairs of groups, but such a bound is"
" implied."
msgstr ""

#: ../../user_guide/mitigation.rst:223
msgid ""
"It is not possible to specify both :code:`difference_bound` *and* "
":code:`ratio_bound` for the same constraint object."
msgstr ""

#: ../../user_guide/mitigation.rst:229
msgid "Demographic Parity"
msgstr ""

#: ../../user_guide/mitigation.rst:231
msgid "A binary classifier :math:`h(X)` satisfies *demographic parity* if"
msgstr ""

#: ../../user_guide/mitigation.rst:233
msgid "\\P[h(X) = 1 \\given A = a] = \\P[h(X) = 1] \\quad \\forall a"
msgstr ""

#: ../../user_guide/mitigation.rst:237
msgid ""
"In other words, the selection rate or percentage of samples with label 1 "
"should be equal across all groups. Implicitly this means the percentage "
"with label 0 is equal as well. In this case, the utility function is "
"equal to :math:`h(X)` and there is only a single event :math:`*`."
msgstr ""

#: ../../user_guide/mitigation.rst:242
msgid ""
"In the example below group :code:`\"a\"` has a selection rate of 60%, "
":code:`\"b\"` has a selection rate of 20%. The overall selection rate is "
"40%, so :code:`\"a\"` is `0.2` above the overall selection rate, and "
":code:`\"b\"` is `0.2` below. Invoking the method :code:`gamma` shows the"
" values of the left-hand sides of the constraints described in "
":ref:`constraints_binary_classification`, which is independent of the "
"provided :code:`difference_bound`. Note that the left-hand sides "
"corresponding to different values of :code:`sign` are just negatives of "
"each other. The value of :code:`y_true` is in this example irrelevant to "
"the calculations, because the underlying utility in demographic parity, "
"selection rate, does not consider performance relative to the true "
"labels, but rather proportions in the predicted labels."
msgstr ""

#: ../../user_guide/mitigation.rst:258
msgid ""
"When providing :code:`DemographicParity` to mitigation algorithms, only "
"use the constructor and the mitigation algorithm itself then invokes "
":code:`load_data`. The example below uses :code:`load_data` to illustrate"
" how :code:`DemographicParity` instantiates inequalities from "
":ref:`constraints_binary_classification`."
msgstr ""

#: ../../user_guide/mitigation.rst:295
msgid ""
"The ratio constraints for the demographic parity with :code:`ratio_bound`"
" :math:`r` (and :code:`ratio_bound_slack=0`) take form"
msgstr ""

#: ../../user_guide/mitigation.rst:298
msgid ""
"r \\leq \\dfrac{\\P[h(X) = 1 \\given A = a]}{\\P[h(X) = 1]} \\leq "
"\\dfrac{1}{r} \\quad \\forall a"
msgstr ""

#: ../../user_guide/mitigation.rst:302
msgid "Revisiting the same example as above we get"
msgstr ""

#: ../../user_guide/mitigation.rst:316
msgid ""
"Following the expressions for the left-hand sides of the constraints, we "
"obtain"
msgstr ""

#: ../../user_guide/mitigation.rst:319
msgid ""
"r \\cdot \\text{utility}_{a,*} - \\text{utility}_* = 0.9 \\times 0.6 - "
"0.4 = 0.14 \\\\\n"
"r \\cdot \\text{utility}_{b,*} - \\text{utility}_* = 0.9 \\times 0.2 - "
"0.4 = -0.22 \\\\\n"
"- \\text{utility}_{a,*} + r \\cdot \\text{utility}_* = - 0.6 + 0.9 "
"\\times 0.4 = -0.24 \\\\\n"
"- \\text{utility}_{b,*} + r \\cdot \\text{utility}_* = - 0.2 + 0.9 "
"\\times 0.4 = 0.16 \\\\"
msgstr ""

#: ../../user_guide/mitigation.rst:330
msgid "True Positive Rate Parity and False Positive Rate Parity"
msgstr ""

#: ../../user_guide/mitigation.rst:332
msgid "A binary classifier :math:`h(X)` satisfies *true positive rate parity* if"
msgstr ""

#: ../../user_guide/mitigation.rst:334
msgid ""
"\\P[h(X) = 1 \\given A = a, Y = 1] = \\P[h(X) = 1 \\given Y = 1] \\quad "
"\\forall a"
msgstr ""

#: ../../user_guide/mitigation.rst:338
msgid "and *false positive rate parity* if"
msgstr ""

#: ../../user_guide/mitigation.rst:340
msgid ""
"\\P[h(X) = 1 \\given A = a, Y = 0] = \\P[h(X) = 1 \\given Y = 0] \\quad "
"\\forall a"
msgstr ""

#: ../../user_guide/mitigation.rst:344
msgid ""
"In first case, we only have one event :math:`Y=1` and ignore the samples "
"with :math:`Y=0`, and in the second case vice versa. Refer to "
":ref:`equalized_odds` for the fairness constraint type that "
"simultaneously enforce both true positive rate parity and false positive "
"rate parity by considering both events :math:`Y=0` and :math:`Y=1`."
msgstr ""

#: ../../user_guide/mitigation.rst:350
msgid "In practice this can be used in a difference-based relaxation as follows:"
msgstr ""

#: ../../user_guide/mitigation.rst:385
msgid ""
"When providing :code:`TruePositiveRateParity` or "
":code:`FalsePositiveRateParity` to mitigation algorithms, only use the "
"constructor. The mitigation algorithm itself then invokes "
":code:`load_data`. The example uses :code:`load_data` to illustrate how "
":code:`TruePositiveRateParity` instantiates inequalities from "
":ref:`constraints_binary_classification`."
msgstr ""

#: ../../user_guide/mitigation.rst:391
msgid "Alternatively, a ratio-based relaxation is also available:"
msgstr ""

#: ../../user_guide/mitigation.rst:408
msgid "Equalized Odds"
msgstr ""

#: ../../user_guide/mitigation.rst:410
msgid ""
"A binary classifier :math:`h(X)` satisfies *equalized odds* if it "
"satisfies both *true positive rate parity* and *false positive rate "
"parity*, i.e.,"
msgstr ""

#: ../../user_guide/mitigation.rst:413
msgid ""
"\\P[h(X) = 1 \\given A = a, Y = y] = \\P[h(X) = 1 \\given Y = y] \\quad "
"\\forall a, y"
msgstr ""

#: ../../user_guide/mitigation.rst:417
msgid ""
"The constraints represent the union of constraints for true positive rate"
" and false positive rate."
msgstr ""

#: ../../user_guide/mitigation.rst:440
msgid "Error Rate Parity"
msgstr ""

#: ../../user_guide/mitigation.rst:442
msgid ""
"The *error rate parity* requires that the error rates should be the same "
"across all groups. For a classifier :math:`h(X)` this means that"
msgstr ""

#: ../../user_guide/mitigation.rst:446
msgid "\\P[h(X) \\ne Y \\given A = a] = \\P[h(X) \\ne Y] \\quad \\forall a"
msgstr ""

#: ../../user_guide/mitigation.rst:450
msgid ""
"In this case, the utility is equal to 1 if :math:`h(X)\\ne Y` and equal "
"to 0 if :math:`h(X)=Y`, and so large value of utility here actually "
"correspond to poor outcomes. The difference-based relaxation specifies "
"that the error rate of any given group should not deviate from the "
"overall error rate by more than the value of :code:`difference_bound`."
msgstr ""

#: ../../user_guide/mitigation.rst:484
msgid ""
"When providing :code:`ErrorRateParity` to mitigation algorithms, only use"
" the constructor. The mitigation algorithm itself then invokes "
":code:`load_data`. The example uses :code:`load_data` to illustrate how "
":code:`ErrorRateParity` instantiates inequalities from "
":ref:`constraints_binary_classification`."
msgstr ""

#: ../../user_guide/mitigation.rst:489
msgid "Alternatively, error rate parity can be relaxed via ratio constraints as"
msgstr ""

#: ../../user_guide/mitigation.rst:491
msgid ""
"r \\leq \\dfrac{\\P[h(X) \\ne Y \\given A = a]}{\\P[h(X) \\ne Y]} \\leq "
"\\dfrac{1}{r} \\quad \\forall a"
msgstr ""

#: ../../user_guide/mitigation.rst:495
msgid ""
"with a :code:`ratio_bound` :math:`r`. The usage is identical with other "
"constraints:"
msgstr ""

#: ../../user_guide/mitigation.rst:513
msgid "Control features"
msgstr ""

#: ../../user_guide/mitigation.rst:515
msgid ""
"The above examples of :class:`Moment` (:ref:`demographic_parity`, "
":ref:`True and False Positive Rate Parity <true_positive_rate_parity>`, "
":ref:`equalized_odds` and :ref:`error_rate_parity`) all support the "
"concept of *control features* when applying their fairness constraints. A"
" control feature stratifies the dataset, and applies the fairness "
"constraint within each stratum, but not between strata. One case this "
"might be useful is a loan scenario, where we might want to apply a "
"mitigation for the sensitive features while controlling for some other "
"feature(s). This should be done with caution, since the control features "
"may have a correlation with the sensitive features due to historical "
"biases. In the loan scenario, we might choose to control for income "
"level, on the grounds that higher income individuals are more likely to "
"be able to repay a loan. However, due to historical bias, there is a "
"correlation between the income level of individuals and their race and "
"gender."
msgstr ""

#: ../../user_guide/mitigation.rst:533
msgid ""
"Control features modify the above equations. Consider a control feature "
"value, drawn from a set of valid values (that is, :math:`c \\in "
"\\mathcal{C}`). The equation given above for Demographic Parity will "
"become:"
msgstr ""

#: ../../user_guide/mitigation.rst:539
msgid ""
"P[h(X) = 1 | A = a, C = c] = P[h(X) = 1 | C = c] \\; \\forall a, c\n"
"\n"
msgstr ""

#: ../../user_guide/mitigation.rst:542
msgid "The other constraints acquire similar modifications."
msgstr ""

#: ../../user_guide/mitigation.rst:548
msgid "Fairness constraints for multi-class classification"
msgstr ""

#: ../../user_guide/mitigation.rst:550
msgid ""
"Reductions approaches do not support multi-class classification yet at "
"this point. If this is an important scenario for you please let us know!"
msgstr ""

#: ../../user_guide/mitigation.rst:556
msgid "Fairness constraints for regression"
msgstr ""

#: ../../user_guide/mitigation.rst:558
msgid ""
"The performance objective in the regression scenario is to minimize the "
"loss of our regressor :math:`h`. The loss can be expressed as "
":class:`SquareLoss` or :class:`AbsoluteLoss`. Both take constructor "
"arguments :code:`min_val` and :code:`max_val` that define the value range"
" within which the loss is evaluated. Values outside of the value range "
"get clipped."
msgstr ""

#: ../../user_guide/mitigation.rst:582
msgid ""
"When using Fairlearn's reduction techniques for regression it's required "
"to specify the type of loss by passing the corresponding loss object when"
" instantiating the object that represents our fairness constraint. The "
"only supported type of constraint at this point is "
":class:`BoundedGroupLoss`."
msgstr ""

#: ../../user_guide/mitigation.rst:590
msgid "Bounded Group Loss"
msgstr ""

#: ../../user_guide/mitigation.rst:592
msgid ""
"*Bounded group loss* requires the loss of each group to be below a user-"
"specified amount :math:`\\zeta`. If :math:`\\zeta` is chosen reasonably "
"small the losses of all groups are very similar. Formally, a predictor "
":math:`h` satisfies bounded group loss at level :math:`\\zeta` under a "
"distribution over :math:`(X, A, Y)` if"
msgstr ""

#: ../../user_guide/mitigation.rst:598
msgid "\\E[loss(Y, h(X)) \\given A=a] \\leq \\zeta \\quad \\forall a"
msgstr ""

#: ../../user_guide/mitigation.rst:602
msgid ""
"In the example below we use :class:`BoundedGroupLoss` with "
":class:`ZeroOneLoss` on two groups :code:`\"a\"` and :code:`\"b\"`. Group"
" :code:`\"a\"` has an average loss of :math:`0.05`, while group "
":code:`\"b\"`'s average loss is :math:`0.5`."
msgstr ""

#: ../../user_guide/mitigation.rst:637
msgid ""
"In the example above the :code:`BoundedGroupLoss` object does not use the"
" :code:`upper_bound` argument. It is only used by reductions techniques "
"during the unfairness mitigation. As a result the constraint violation "
"detected by :code:`gamma` is identical to the mean absolute error."
msgstr ""

#: ../../user_guide/mitigation.rst:645
msgid "Exponentiated Gradient"
msgstr ""

#: ../../user_guide/mitigation.rst:650
msgid "Grid Search"
msgstr ""

#: ../../user_guide/mitigation.rst:654
msgid ""
"Agarwal, Dudik, Wu `\"Fair Regression: Quantitative Definitions and "
"Reduction-based Algorithms\" <https://arxiv.org/pdf/1905.12843.pdf>`_, "
"ICML, 2019."
msgstr ""

#: ../../user_guide/mitigation.rst:658
msgid ""
"Agarwal, Beygelzimer, Dudik, Langford, Wallach `\"A Reductions Approach "
"to Fair Classification\" <https://arxiv.org/pdf/1803.02453.pdf>`_, ICML, "
"2018."
msgstr ""

#: ../../user_guide/mitigation.rst:662
msgid ""
"Hardt, Price, Srebro `\"Equality of Opportunity in Supervised Learning\" "
"<https://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-"
"learning.pdf>`_, NeurIPS, 2016."
msgstr ""

